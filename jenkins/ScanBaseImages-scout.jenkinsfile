@Library('datacommons-jenkins-shared-library@v1.2') _
import groovy.json.JsonSlurper

pipeline {
	agent {
		node {
			label 'slave-ncias-d2940-c'
		}
	}

  parameters {

  string(defaultValue: "michael.fleming@nih.gov,zhengwu.lu@nih.gov,cole.devries@nih.gov", 
        description: 'Enter a list of email addresses to notify with results:', 
        name: 'EmailRecipients')

  }
  
  environment {

	CODE_REPO      = "datacommons-devops"
	CODE_FOLDER    = "datacommons-devops"
	CODE_BRANCH    = "main"

	ECR_REPO       = "cbiit-base-docker-images"
	REGION         = "us-east-1"

	API_URI        = "https://api.github.com"
	ORG            = "CBIIT"

	BASE_IMAGE_TAG = "fnl_base_image"

  }

  stages{
  	stage('checkout'){
  		steps {

		checkout([$class: 'GitSCM',
			branches: [[name: "${env.CODE_BRANCH}"]],
			extensions: [[$class: 'SubmoduleOption', 
			recursiveSubmodules: true],
			[$class: 'RelativeTargetDirectory',
			relativeTargetDir: "${env.CODE_FOLDER}"]],
			userRemoteConfigs:
			[[url: "https://github.com/CBIIT/${env.CODE_REPO}"]]])

        }

  	}

   stage('Image List'){

 		steps {

 			script {
				// set ECR account number
				env.GITHUB_USER = sh(label: 'Get User', returnStdout: true, script: "aws secretsmanager get-secret-value --region 'us-east-1' --secret-id github/pat --query SecretString --output text | jq -r '.user'").trim()
				env.GITHUB_PAT = sh(label: 'Get PAT', returnStdout: true, script: "aws secretsmanager get-secret-value --region 'us-east-1' --secret-id github/pat --query SecretString --output text | jq -r '.token'").trim()
				
				// get list of all base images found in CBIIT repos
				maskPasswords(varPasswordPairs: [[password: "${env.GITHUB_PAT}"]]){
					headers = "Authorization: token $GITHUB_PAT"
					println "$headers"

					//REPO_NB_PAGES=sh(label: 'Get repo pages', returnStdout: true, script: "curl -u $GITHUB_USER:$GITHUB_PAT -I -s $API_URI/orgs/$ORG/repos\\?page\\=1\\&per_page\\=\\100 | sed -nr 's/^Link:.*page=([0-9]+)&per_page=100.*/\\1/p'").trim()
					REPO_NB_PAGES=sh(label: 'Get repo pages', returnStdout: true, script: "curl -h $headers -I -s $API_URI/orgs/$ORG/repos\\?page\\=1\\&per_page\\=\\100 | sed -nr 's/^Link:.*page=([0-9]+)&per_page=100.*/\\1/p'").trim()
					println "Repo Pages:  ${REPO_NB_PAGES}"

					def dockerFiles = []
					def baseImages = []

					def page = 1
					while(page <= REPO_NB_PAGES) {
						//repos = sh(label: 'get repo names', returnStdout: true, script: "curl -u $GITHUB_USER:$GITHUB_PAT -s $API_URI/orgs/$ORG/repos\\?page=$page\\&per_page\\=\\100  | jq -r -c '.[].name'").trim().split()
						repos = sh(label: 'get repo names', returnStdout: true, script: "curl -h $headers -s $API_URI/orgs/$ORG/repos\\?page=$page\\&per_page\\=\\100  | jq -r -c '.[].name'").trim().split()

						repos.each() {
							println "Repo:     $it"
							
							//tree = sh(label: 'get tree url', returnStdout: true, script: "curl -u $GITHUB_USER:$GITHUB_PAT -s $API_URI/repos/$ORG/$it | grep -m1 trees_url | grep $ORG | sed 's/^.*\\(https.*trees\\).*\$/\\1/'").trim()
							tree = sh(label: 'get tree url', returnStdout: true, script: "curl -h $headers -s $API_URI/repos/$ORG/$it | grep -m1 trees_url | grep $ORG | sed 's/^.*\\(https.*trees\\).*\$/\\1/'").trim()
							
							// get all branches for this repo
							//branch_list = sh(label: 'get default branch', returnStdout: true, script: "curl -u $GITHUB_USER:$GITHUB_PAT -s $API_URI/repos/$ORG/$it/branches | jq -r -c '.[].name' | sed 's:\\([()]\\+\\):\\\1:g'").trim().split()
							branch_list = sh(label: 'get default branch', returnStdout: true, script: "curl -h $headers -s $API_URI/repos/$ORG/$it/branches | jq -r -c '.[].name' | sed 's:\\([()]\\+\\):\\\1:g'").trim().split()
							branch_list.each { branch ->

								//repo_empty = sh(label: 'check repo status', returnStdout: true, script: "curl -u $GITHUB_USER:$GITHUB_PAT -s $tree/$branch\\?recursive\\=1 | grep -i 'Git Repository is empty' || true")
								repo_empty = sh(label: 'check repo status', returnStdout: true, script: "curl -h $headers -s $tree/$branch\\?recursive\\=1 | grep -i 'Git Repository is empty' || true")

								if (! repo_empty) {
								
								//dockerfilePath = sh(label: 'get dockerfile url', returnStdout: true, script: "curl -u $GITHUB_USER:$GITHUB_PAT -s $tree/$branch\\?recursive\\=1 | jq -r '.tree[] | select(.path | ascii_downcase | contains(\"dockerfile\"))? |.path' || echo 'NOT_FOUND'").trim().split()
								dockerfilePath = sh(label: 'get dockerfile url', returnStdout: true, script: "curl -h $headers -s $tree/$branch\\?recursive\\=1 | jq -r '.tree[] | select(.path | ascii_downcase | contains(\"dockerfile\"))? |.path' || echo 'NOT_FOUND'").trim().split()
								rawUrl =  "https://raw.githubusercontent.com/$ORG/$it/$branch"

								if (!(dockerfilePath == 'NOT_FOUND')) {
									repo_name = it
									dockerfilePath.each() {
										base_image = sh(label: 'get dockerfile base image', returnStdout: true, script: "curl -s -J $rawUrl/$it | grep FROM | grep $BASE_IMAGE_TAG || echo 'NOT_FOUND'").trim()
										if (!(base_image == 'NOT_FOUND')) {
											base_image = base_image.substring(base_image.indexOf(" ") + 1).trim()
											base_image = base_image.substring(0, base_image.indexOf(" ")).trim()
											image_info = [Name:base_image, Projects:"$repo_name:$branch"]
											println "Base Image:   $base_image"
											baseImages.add(image_info)
										}
									}
								}
								
								}
							}
						}
						page++
					}

					// consolidate base image list to remove duplicate entries
					imageList = []
					baseImages.each { image ->
					  def currentImage = imageList.find{ it.Name == image.Name }
					  if( !(currentImage == null) ) {
						currentImage.Projects += ", $image.Projects"
					  } else {
						imageList.add(image)
					  }
					}

				}

			}

 		}

  	}

	stage('Image Scans'){

 		steps {

 			script {
				// get docker creds
				env.DOCKER_USER = sh(label: 'Get User', returnStdout: true, script: "aws secretsmanager get-secret-value --region 'us-east-1' --secret-id docker/pat --query SecretString --output text | jq -r '.user'").trim()
				env.DOCKER_PAT = sh(label: 'Get PAT', returnStdout: true, script: "aws secretsmanager get-secret-value --region 'us-east-1' --secret-id docker/pat --query SecretString --output text | jq -r '.token'").trim()

				RESULTS = ""
				IMAGES = ""

				// Add image list to RESULTS
				IMAGES += "Images Scanned:\n\n"
				imageList.each { image ->
					IMAGES += "Name:  $image.Name     Projects:  $image.Projects\n"

				}

				docker_login=sh(label: 'Get scan results', returnStdout: true, script: "docker login -u $DOCKER_USER -p $DOCKER_PAT").trim()

				imageList.each { image ->
					scout_out=sh(label: 'Get scan results', returnStdout: true, script: "docker scout cves --only-severity critical,high $image.Name").trim()
					if (!(scout_out.contains("No vulnerable packages detected"))) {
					    RESULTS += "\n\nResults: $image.Projects\n$scout_out\n\n"
						RESULTS += "############################################################################################################################"
					}

				}

				println IMAGES
				println RESULTS

				if(RESULTS) {
                    catchError(stageResult: 'FAILURE') {
                        error 'VULNERABILITIES FOUND'
                    }
					RESULTS = IMAGES + RESULTS
				}

			}

 		}

  	}


  }

  post {

	failure {

		script {

			RESULTS_FILE = sh(label: 'Get results file name', returnStdout: true, script: "echo results_\$(date '+%Y%m%d').txt").trim()
			writeFile(file: RESULTS_FILE, text: RESULTS)

		}
		
		emailext(attachmentsPattern: 'results_*.txt',
			mimeType: 'text/html',
			body: "Base Image scan results attached",
			subject: "Base Image Vulnerabilities Found",
			to: "${EmailRecipients}")
    }

    cleanup {

        cleanWs()

    }

  }

}